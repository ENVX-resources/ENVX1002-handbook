{
  "hash": "37ade7f94a9bba8b22427196a581e002",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Lab 06 -- Two-sample *t*-test\nembed-resources: true\nresources:\n  - data/Barley.csv\n  - data/Plant_growth.csv\n  - data/Turbidity.csv\n---\n\n\n\n\n\n\n::: callout-tip\n## Learning outcomes\n\n-   Learn to use R to calculate a 2-sample *t*-test\n    -   independent samples with constant variance\n    -   independent samples with unequal variance\n    -   paired samples\n    -   data transformations\n-   Apply the steps for hypothesis testing from lectures\n-   Learn how to interpret statistical output\\\n:::\n\n## Before you begin\n\nCreate your Quarto document and save it as `Lab-06.Rmd` or similar. The following data files are required:\n\n1)  [Barley.csv](data/Barley.csv)\n2)  [Plant_growth.csv](data/Plant_growth.csv)\n3)  [Turbidity.csv](data/Turbidity.csv)\n\nThe following external packages are used in this lab. Install them if you have not done so already.\n\n``` r\ninstall.packages(c(\"tidyverse\", \"car\"), \n  repo = \"https://cloud.r-project.org\")\n```\n\nFinally, try to complete today's lab exercises in pairs and try out [pair programming](https://en.wikipedia.org/wiki/Pair_programming), where one person writes the code and the other person reviews each line as it is written. You can swap roles every 10 minutes or so. This is a great way to learn from each other and to improve your coding skills.\n\n## Exercise 1: barley (walk-through)\n\n### Background\n\nAn experiment was designed to compare two varieties of spring barley. Thirty four plots were used, seventeen being randomly allocated to variety A and seventeen to variety B. Unfortunately five plots were destroyed. The yields (t/ha) from the remaining plots were as they appear in the file `Barley.csv`.\n\n### Instructions\n\nFirst, quickly explore the data; then, utilise the **HATPC** process and test the hypothesis that the two varieties give equal yields, assuming that the samples are independent.\n\n::: column-margin\nHATPC:\n\n-   Hypothesis\n-   Assumptions\n-   Test (statistic)\n-   P-value\n-   Conclusion\n:::\n\n::: callout-note\n## Level of significance\n\n**The level of significance is usually set at 0.05.** This value is generally accepted in the scientific community and is also linked to Type 2 errors, where choosing a lower significance increases the likelihood of failing to reject the null hypothesis when it is false.\n:::\n\n### Data exploration\n\nFirst we load the data and inspect its structure to see if it needs to be cleaned or transformed. The `glimpse()` function is a tidy version of `str()` that provides a quick overview of the data that focuses on the variables, ignoring data attributes.\n\n::: column-margin\nTry to compare `str()` and `glimpse()` to see what the differences are.\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbarley <- readr::read_csv(\"data/Barley.csv\") # packagename:: before a function lets you access a function without having to load the whole library first\ndplyr::glimpse(barley)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 29\nColumns: 2\n$ Variety <chr> \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A…\n$ Yield   <dbl> 4.6, 4.3, 3.8, 3.4, 3.9, 3.9, 3.9, 4.4, 3.6, 3.6, 4.7, 3.9, 3.…\n```\n\n\n:::\n:::\n\n\n\n\nThe `Variety` column is a factor with two levels, `A` and `B`, but it is defined as a character. We can convert it to a factor using the `mutate()` function from the `dplyr` package, but it is not necessary for the *t*-test since R will automatically convert it to a factor.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nbarley <- mutate(barley, Variety = as.factor(Variety))\n```\n:::\n\n\n\n\nQuickly preview the data as a plot to see if there are any trends or unusual observations.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbarley %>%\n  ggplot(aes(x = Variety, y = Yield)) +\n  geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](Lab06_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\n\n\nA trained eye will anticipate that the data may not meet the assumption of equal variance; however, we will test this assumption later. Otherwise, there appear to be no unusual observations in the data.\n\n### Hypothesis\n\nWhat are the null and alternative hypotheses? We can use the following notation:\n\n$$H_0: \\mu_A = \\mu_B$$ $$H_1: \\mu_A \\neq \\mu_B$$\n\nwhere $\\mu_A$ and $\\mu_B$ are the population means of varieties A and B, respectively.\n\n::: column-margin\nIt is **important** that when using mathematical symbols to denote the null and alternative hypotheses, you should **always** define what the symbols mean. Otherwise, the reader may not understand what you are referring to.\n:::\n\nThe equations above are written in LaTeX, a typesetting system that is commonly used in scientific writing. You can learn more about LaTeX [here](https://www.latex-project.org/). The raw syntax used to write the equations are shown below:\n\n``` markdown\n$$H_0: \\mu_A = \\mu_B$$\n$$H_1: \\mu_A \\neq \\mu_B$$\n```\n\n**Why do we always define the null and alternative hypotheses?** In complex research projects or when working in a team, it is important to ensure that everyone is on the same page. By defining the hypotheses, you can avoid misunderstandings and ensure that everyone is working towards the same goal as the mathematical notation is clear and unambiguous.\n\n### Assumptions\n\n#### Normality\n\nThere are many ways to check for normality. Here we will use the QQ-plot. Use of `ggplot2` is preferred (as a means of practice) but since we are just exploring data, base R functions are not a problem to use.\n\n::: panel-tabset\n## Using `ggplot2`\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(barley, aes(sample = Yield)) +\n  stat_qq() +\n  stat_qq_line() +\n  facet_wrap(~Variety) #facet_wrap ensures there are separate plots for each variety rather than one plot with all the data in Yield \n```\n\n::: {.cell-output-display}\n![](Lab06_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n\n\n## Using base R\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npar(mfrow = c(1, 2))\nqqnorm(barley$Yield[barley$Variety == \"A\"], main = \"Variety A\") # square brackets to subset the data by variety\nqqline(barley$Yield[barley$Variety == \"A\"])\nqqnorm(barley$Yield[barley$Variety == \"B\"], main = \"Variety B\")\nqqline(barley$Yield[barley$Variety == \"B\"])\n```\n\n::: {.cell-output-display}\n![](Lab06_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n\n:::\n\n**Question**: Do the plots indicate the data are normally distributed?\n\n**Answer**: Yes, the data appear to be normally distributed as the QQ-plot shows that the data points are close to the line.\n\n#### Homogeneity of variance\n\nFrom the boxplot, we can see that there is some indication that the variances are not equal. We can test this assumption using Bartlett's test or Levene's test; here we will just use Bartlett's test.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbartlett.test(Yield ~ Variety, data = barley)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tBartlett test of homogeneity of variances\n\ndata:  Yield by Variety\nBartlett's K-squared = 14.616, df = 1, p-value = 0.0001318\n```\n\n\n:::\n:::\n\n\n\n\n**Question**: Does the Bartlett's test indicate the two groups have equal variances? What effect will that have on the analysis?\n\n**Answer**: The two groups have unequal variance (Bartlett's test: $X^2 = 14.6$, $p < 0.01$). This means that we will need to use the Welch's *t*-test, which does not assume equal variances.\n\n### Test statistic\n\nWe can now calculate the test statistic using the `t.test()` function in R. Since the variances are unequal, we do not have to specify the `var.equal` argument -- the default test for `t.test()` is the Welch's *t*-test which does not assume equal variances.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt.test(Yield ~ Variety, data = barley)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tWelch Two Sample t-test\n\ndata:  Yield by Variety\nt = -4.9994, df = 19.441, p-value = 7.458e-05\nalternative hypothesis: true difference in means between group A and group B is not equal to 0\n95 percent confidence interval:\n -0.9293569 -0.3814274\nsample estimates:\nmean in group A mean in group B \n       4.052941        4.708333 \n```\n\n\n:::\n:::\n\n\n\n\n### P-value\n\nSince the p-value is \\< 0.05, we can reject the null hypothesis that the mean yield of both varieties is equal.\n\n### Conclusion\n\nThe conclusion needs to be brought into the context of the study. In a scientific report or paper, you would write something like this:\n\n> The mean yield of barley variety A was significantly different from that of variety B ($t = -5.0$, $df = 19.4$, $p < 0.01$).\n\n## Exercise 2: plant growth\n\n### Background\n\nIn a test of a particular treatment aimed at inducing growth, 20 plants were grouped into ten pairs so that the two members of each pair were as similar as possible. One plant of each pair was chosen randomly and treated; the other was left as a control. The increases in height (in centimetres) of plants over a two-week period are given in the file Two week plant heights. We wish to compare whether the treatment is actually inducing improved growth, as compared to the control.\n\n### Instructions\n\nHere, we have two samples, and the samples are paired as it is a before-after experiment. So we’d like to conduct a paired *t*-test.\n\nFor paired *t*-tests the analysis is performed as a 1-sample *t*-test on the difference between each pair so the only assumption is the normality assumption.\n\nCopy the structure below and perform your analysis in your document.\n\n``` md\n## Exercise 2: plant growth\n### Data exploration\n### Hypothesis\n### Assumptions\n#### Normality\n#### Homogeneity of variance\n### Test statistic\n### P-value\n### Conclusion\n```\n\nNote that the data is *not* tidy. The code below will convert the data to the long format and assign it to `tidy_plant`.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplant_growth <- readr::read_csv(\"data/Plant_growth.csv\")\n\ntidy_plant <- plant_growth %>%\n  pivot_longer(cols = c(Treated, Control), names_to = \"Treatment\", values_to = \"Height\")\n```\n:::\n\n\n\n\nYou may also need to perform a Shapiro-Wilk test to check for normality. To do this for each group, you can use the `tapply()` function.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntapply(tidy_plant$Height, tidy_plant$Treatment, shapiro.test)\n```\n:::\n\n\n\n\n::: {.content-visible when-profile=\"solution\"}\n## Answer 2 {style=\"color:green;\"}\n\n### Data exploration {style=\"color:green;\"}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Boxplot\nggplot(tidy_plant, aes(x = Treatment, y = Height)) +\n  geom_boxplot()\n```\n:::\n\n\n\n\nThe boxplot shows no unusual observations.\n\n### Hypothesis {style=\"color:green;\"}\n\n$$H_0: \\mu_{\\text{treated}} = \\mu_{\\text{control}}$$ $$H_1: \\mu_{\\text{treated}} \\neq \\mu_{\\text{control}}$$\n\nwhere $\\mu_{\\text{treated}}$ and $\\mu_{\\text{control}}$ are the mean increses in height of the treated and control plants, respectively.\n\n### Assumptions {style=\"color:green;\"}\n\n#### Normality {style=\"color:green;\"}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#qqplots\nggplot(tidy_plant, aes(sample = Height)) +\n  stat_qq() +\n  stat_qq_line() +\n  facet_wrap(~Treatment)\n```\n:::\n\n\n\n\nThe QQ-plots show that the data are normally distributed, but there are some outliers worth checking. A formal test for normality will give us a better idea of whether the assumption is met.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# perform test on groups\ntapply(tidy_plant$Height, tidy_plant$Treatment, shapiro.test)\n```\n:::\n\n\n\n\nThe Shapiro-Wilk test indicates that the data are normally distributed.\n\n#### Homogeneity of variance {style=\"color:green;\"}\n\nThere is **no need** to test for homogeneity of variance in a paired *t*-test!\n\n### Test statistic {style=\"color:green;\"}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt.test(tidy_plant$Height[tidy_plant$Treatment == \"Treated\"],\n  tidy_plant$Height[tidy_plant$Treatment == \"Control\"],\n  paired = TRUE\n)\n```\n:::\n\n\n\n\n### P-value {style=\"color:green;\"}\n\nThe p-value is 0.03 which is less than 0.05, so we reject the null hypothesis that the mean increase in height of the treated and control plants is equal.\n\n### Conclusion {style=\"color:green;\"}\n\nThe mean increase in height of the treated plants is significantly different from that of the control plants ($t = 2.5$, $df = 9$, $p = 0.03$).\n:::\n\n## Exercise 3: turbidity\n\n### Background\n\nA new filtering process was installed at a dam which provided drinking water for a nearby town. To check on its success, a number of water samples were taken at random times and locations in the weeks before and after the process was installed. The following are the turbidity values (units = NTU) of the water samples.\n\n### Instructions\n\nNow we consider further examples of a two-sample *t*-test, but where the assumption of equal variance and normality may not be met for the raw data. Sometimes after applying a data transformation the analysis can proceed assuming equal variances -- but always check after a data transformation.\n\nThe data can be read with the code below:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nturbidity <-read_csv(\"data/Turbidity.csv\")\n```\n:::\n\n\n\n\nFor data transformation, you may need to create a new variable in your dataset to store the transformed data. For example, to create a new variable `TurbLog10` that stores the log~10~ transformed turbidity values, you can use the following code:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nturbidity$TurbLog10 <- log10(turbidity$Turbidity)\n```\n:::\n\n\n\n\nTo interpret the results for your conclusions, you may need to back-transform the mean and/or confidence interval values. To back transform log~10~ data you use:\n\n$$10^{\\text{mean or CI}}$$\n\nTo back-transform natural log, log~e~, you use:\n\n$$e^{\\text{mean or CI}}$$\n\n::: {.content-visible when-profile=\"solution\"}\n## Answer 3 {style=\"color:green;\"}\n\n### Data exploration {style=\"color:green;\"}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Read in data\nturbidity <- read_csv(\"data/Turbidity.csv\")\n\n#Make boxplot\nggplot(turbidity, aes(x = Time, y = Turbidity)) +\n  geom_boxplot()\n```\n:::\n\n\n\n\nThe boxplot shows skewing of the data, and outliers, a strong indication that the data will have issues meeting the assumption of normality. It is also likely that the variances are not equal as the boxplot shows different spreads.\n\n### Hypothesis {style=\"color:green;\"}\n\n$$H_0: \\mu_{\\text{before}} = \\mu_{\\text{after}}$$ $$H_1: \\mu_{\\text{before}} \\neq \\mu_{\\text{after}}$$\n\nwhere $\\mu_{\\text{before}}$ and $\\mu_{\\text{after}}$ are the mean turbidity values before and after the new filtering process was installed.\n\n### Assumptions {style=\"color:green;\"}\n\n#### Normality: part 1 {style=\"color:green;\"}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#qqplots\nggplot(turbidity, aes(sample = Turbidity)) +\n  stat_qq() +\n  stat_qq_line() +\n  facet_wrap(~Time)\n```\n:::\n\n\n\n\nThe QQ-plots show that the data are not normally distributed. Transformation of the data is required – there is no need to look at the equal variances just yet.\n\n#### Transform data {style=\"color:green;\"}\n\nWe will use the natural log transformation to normalise the data.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nturbidity$TurbLog10 <- log10(turbidity$Turbidity)\n```\n:::\n\n\n\n\n#### Normality: part 2 {style=\"color:green;\"}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(turbidity, aes(sample = TurbLog10)) +\n  stat_qq() +\n  stat_qq_line() +\n  facet_wrap(~Time)\n```\n:::\n\n\n\n\nThe QQ-plots show that the data look better. We can now perform a Shapiro-Wilk test to confirm this.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntapply(turbidity$TurbLog10, turbidity$Time, shapiro.test)\n```\n:::\n\n\n\n\nThe Shapiro-Wilk test indicates that the data are normally distributed.\n\n#### Homogeneity of variance {style=\"color:green;\"}\n\nWe check the assumption of equal variance after the transformation.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbartlett.test(TurbLog10 ~ Time, data = turbidity)\n```\n:::\n\n\n\n\nThe Bartlett's test indicates that the variances are equal. We can now perform the *t*-test on the transformed data.\n\n### Test statistic {style=\"color:green;\"}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt.test(TurbLog10 ~ Time, data = turbidity, var.equal = TRUE)\n```\n:::\n\n\n\n\n### P-value {style=\"color:green;\"}\n\nThe p-value is 0.007, which is less than 0.05, so we reject the null hypothesis that the mean turbidity values before and after the new filtering process was installed are equal.\n\n### Conclusion {style=\"color:green;\"}\n\nWe want to make a biological conclusion based on the results. To do this, we need to back-transform the mean difference and the confidence intervals so that the units are in NTU, not log~10~ NTU.\n\n#### Mean difference {style=\"color:green;\"}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n10^(1.514274 - 0.683656)\n```\n:::\n\n\n\n\n#### Lower and upper CI {style=\"color:green;\"}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n10^(0.359140)\n10^(1.302095)\n```\n:::\n\n\n\n\nThe mean turbidity values before and after the new filtering process was installed are significantly different ($t = -3.7$, $df = 17$, $p = 0.007$). The new filtering process has effectively reduced turbidity by 7 NTU on average. We are 95% confident that the new filtering process will reduce water turbidity by between 2.3 and 20 NTU.\n:::\n",
    "supporting": [
      "Lab06_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}