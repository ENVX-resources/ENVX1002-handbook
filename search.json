[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ENVX1002 Handbook",
    "section": "",
    "text": "Preface\nWelcome to the ENVX1002 handbook. This handbook is designed to be an optional companion to the lectures, labs and assessments for the course.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#how-to-use-this-handbook",
    "href": "index.html#how-to-use-this-handbook",
    "title": "ENVX1002 Handbook",
    "section": "How to use this handbook",
    "text": "How to use this handbook\nRead this handbook before, or after each lecture to better understand certain concepts. You can also use this book as a reference when working on lab exercises and assessments.\nYou may download a PDF copy of this handbook on the sidebar of the HTML version of this book. You may also download the source code for this book from the GitHub repository.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#acknowledgements",
    "href": "index.html#acknowledgements",
    "title": "ENVX1002 Handbook",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nWe would like to acknowledge the work of previous generations of teaching staff who created the bulk of the teaching material within this manual. In particular, the work of:\n\nAssoc. Prof. Mick O’Neill\nDr. Kathryn Aufflick\nAssoc. Prof. Peter Thomson\nProf. Thomas Bishop\n\nWhen you are ready, check the sidebar to get started.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "020-exploring_data.html",
    "href": "020-exploring_data.html",
    "title": "1  Exploratory Data Analysis EDA",
    "section": "",
    "text": "1.1 Numerical Summaries\nThe summary descriptive characteristics of a sample of objects, that is, a subset of the population, are called statistics. Sample statistics can have different values, depending on how the sample of the population was chosen. Statistics are denoted by various symbols, but (almost) never by Greek letters e.g. sample mean, \\(\\bar y\\) and sample standard deviation, \\(s\\).",
    "crumbs": [
      "Describing data",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Exploratory Data Analysis EDA</span>"
    ]
  },
  {
    "objectID": "020-exploring_data.html#numerical-summaries",
    "href": "020-exploring_data.html#numerical-summaries",
    "title": "1  Exploratory Data Analysis EDA",
    "section": "",
    "text": "1.1.1 Measures of Central Tendency\nThese statistics are also sometimes referred to as measures of location.\nARITHMETIC MEAN\nThe most widely used measure of central tendency is the arithmetic mean or average. The population mean, \\(\\mu\\) (“mu”) is the sum of all the values of the variable under study divided by the total number of objects in the population, Each value is algebraically denoted by a \\(y\\) with a subscript denotation \\(i\\). E.g. a small theoretical population whose objects had values 1, 6, 4, 5, 6, 3, 8, 7 would be denoted:\n\\[y_1 = 1,\\ y_2 = 6,\\ y_3 = 4,\\ y_4 = 5,\\ y_5 = 6,\\ y_6 = 3,\\ y_7 = 8,\\ y_8 = 7\\]\n\n\n\n\n\n\nNote\n\n\n\nSome texts will use \\(X\\) instead of \\(x\\) or \\(Y\\) instead of \\(y\\) as the symbol for a value.\n\n\nWe would denote the population size with a capital \\(N\\). In our theoretical population \\(N = 8\\).\nThe population mean, \\(\\mu\\), would be:\n\\[\\frac{1+6+4+5+6+3+8+7}{8}=5\\]\nThe algebraic shorthand formula for a population mean is\n\\[\\mu = \\frac{1}{N}\\sum_{i=1}^{N} y_i\\]\nThe Greek letter \\(\\Sigma\\) (“sigma”) indicates summation, the subscript \\(i = 1\\) means to start with the first observation, and the superscript \\(N\\) means to continue until and including the \\(N\\)th observation.\nFor the example above,\n\\[\\sum_{i=2}^{5} y_i=y_2+y_3+y_4+y_5=6+4+5+6=21\\]\nTo reduce the clutter, if the summation sign is not indexed, for example \\(y_i\\), it is implied that the operation of addition begins with the first observation and continues through the last observation in a population, that is,\n\\[\\sum_{i=1}^{N} y_i = \\sum y_i\\]\nThe sample mean is defined by\n\\[\\bar y = \\frac{1}{n}\\sum_{i=1}^{n} y_i\\]\nwhere \\(n\\) is the sample size.\nThe symbol \\(\\bar y\\) (read “y bar”) indicates that the observations of a subset of size n from a population have been averaged. \\(y\\) is fundamentally different from \\(\\mu\\) because samples from a population can have different values for their sample mean, that is, they can vary from sample to sample within the population. The population mean, however, is constant for a given population.\nAgain consider the small theoretical population \\(1, 6, 4, 5, 6, 3, 8, 7\\). A sample size of 3 may consist of \\(5, 3, 4\\) with \\(\\bar y =6\\) OR it could be \\(1,3,5\\) with \\(\\bar y = 3\\)\nEach sample mean \\(\\bar y\\) is an unbiased estimate of \\(m\\) but depends on the values included in the sample and sample size for its actual value. We would expect the average of all possible \\(y\\)’s to be equal to the population parameter, \\(\\mu\\). This is, in fact, the definition of an unbiased estimator of the population mean.\nThe R function is mean().\n\ny &lt;- c(1, 6, 4, 5, 6, 3, 8, 7)\nmean(y)\n\n[1] 5\n\n\nThe Excel command is =AVERAGE()\nMEDIAN\nThe median is the “middle” value of an ordered list of observations. The population median \\(M\\) is the \\(\\left( \\frac{N+1}{2} \\right)th\\) sorted value, where \\(N\\) is the population size. Note that this parameter is not a Greek letter and is seldom computed in practice. A sample median \\(\\tilde y\\) (read “y tilde”) is the statistic used to approximate or estimate the population median. \\(\\tilde y\\) is the \\(\\left( \\frac{n+1}{2} \\right)th\\) sorted value where n is the sample size.\nThe R function is median().\n\ny &lt;- c(1, 6, 4, 5, 6, 3, 8, 7)\nmedian(y)\n\n[1] 5.5\n\n\nThe Excel command is =MEDIAN().\nMODE\nThe mode is the most frequently occurring value in a data set.\nThere is no direct function for the mode in R, the following code is an example of how it can be calculated.\n\nmode_function &lt;- function(x) {\n  uniqx &lt;- unique(x)\n  uniqx[which.max(tabulate(match(x, uniqx)))]\n}\n\n# Example usage\ny &lt;- c(1, 6, 4, 5, 6, 3, 8, 7)\nmode &lt;- mode_function(y)\nprint(mode)\n\n[1] 6\n\n\nThe Excel command is =MODE().\nOVERVIEW OF MEASURES OF CENTRAL TENDENCY:\n\nThe mean is a purposeful measure only for a quantitative variable, whether it is continuous (e.g. height) or discrete (e.g. number of nematodes).\nThe median can be calculated whenever a variable can be ranked (including when the variable is quantitative).\nThe mode can be calculated for categorical variables, as well as for quantitative and ranked variables.\nThe sample median expresses less information than the sample mean because it utilizes the ranks and not the actual values of each measurement.\nThe median, however, is resistant to the effects of outliers. Extreme values or outliers in a sample can drastically affect the sample mean, while having little effect on the median.\n\n\n\n1.1.2 Measures of Spread\nMeasures of central tendency alone are not sufficient to fully describe a data set. The following figure illustrates 3 distributions that all have the same mean but different levels of dispersion or spread.\n\nlibrary(ggplot2)\n\n# Define the data for the three normal distributions\nmean_value &lt;- 0\nstd_dev_A &lt;- 1   # Least spread\nstd_dev_B &lt;- 2\nstd_dev_C &lt;- 3   # Most spread\n\n# Create a data frame for plotting\nx_values &lt;- seq(-10, 10, length.out = 300)\nnormal_data &lt;- data.frame(\n  x = c(x_values, x_values, x_values),\n  y = c(dnorm(x_values, mean_value, std_dev_A), \n        dnorm(x_values, mean_value, std_dev_B), \n        dnorm(x_values, mean_value, std_dev_C)),\n  curve = factor(c(rep(\"A\", length(x_values)), \n                   rep(\"B\", length(x_values)), \n                   rep(\"C\", length(x_values)))\n  )\n)\n\n# Generate the plot\nggplot(normal_data, aes(x = x, y = y, color = curve)) +\n  geom_line() +\n  labs(title = \"Normal Distributions with Different Spreads\",\n       x = \"Value\",\n       y = \"Density\") +\n  scale_color_manual(values = c(\"red\", \"green\", \"blue\"),\n                     labels = c(\"A: Least Spread\", \"B\", \"C: Most Spread\")) +\n  theme_minimal()\n\n\n\n\nFigure 1.1 A, B & C are distributions with the same mean (zero) but varying standard deviations.\n\n\n\n\nIn graph A, most of the values are concentrated around the mean. It has less dispersion (or spread of values) than the other distributions. Graph C has more dispersion than the others. Its data is more “spread” out. A measure of dispersion provides some indication of the amount of variation that the data exhibits.\nRANGE\nThe simplest measure of dispersion or “spread” is the range – the difference between the largest and smallest observations in a group of data.\nThe sample range is a crude and biased estimator of the population range as its dependent on the composition and size of the sample you’ve taken. [It’s unlikely that the sample will include the largest and smallest values from the population, so the sample range usually underestimates the population range and is, therefore, a biased estimator.]\nThe R function is max(y)-min(y)\n\ny &lt;- c(1, 6, 4, 5, 6, 3, 8, 7)\nmax(y)-min(y)\n\n[1] 7\n\n\nThe Excel command is =MAX()-MIN()\nINTERQUARTILE RANGE\nRather than describe variability in terms of variation around the mean, we more directly quantify the “spread”. Just as the median divides the sample into two, the quartiles divide the sample into four groups:\n\n25% of observations \\(\\le\\) lower quartile (Q1)\n50% of observations \\(\\le\\) median (Q2)\n75% of observations \\(\\le\\) upper quartile (Q3)\n\nThe example data below (the number of days pigs take to reach bacon weight) has been sorted from lowest to highest.\n98 100 100 103 105 107 110 113 115\nThe lower quartile Q1 is the \\(\\left( \\frac{n+1}{4} \\right)th\\) sorted value = \\(\\left( \\frac{9+1}{4} \\right)th = 2.5th\\) sorted value.\nThis means we need to obtain a weighted average of the 2nd and 3rd sorted value: \\[0.5 \\times 100 + 0.5 \\times 100 = 100 \\text{ days}\\]\nThe upper quartile Q3 is the \\(\\left( \\frac{3(n+1)}{4} \\right)th\\) sorted value = \\(\\left( \\frac{3(9+1)}{4} \\right)th = 7.5th\\) sorted value.\nThis means we need to obtain a weighted average of the 2nd and 3rd sorted value: \\[0.5 \\times 110 + 0.5 \\times 113 = 111.5 \\text{ days}\\]\nThe inter quartile range = Upper Quartile - Lower Quartile\n\\[IQR = Q3-Q1=111.5-100=11.5 \\text{ days}\\]\nSo 50% of pigs reach bacon weight within a range of 11.5 days.\nThe following is an example of calculations in R - note that we use the type 6 calculation and the default in R is type 7 which we generally use.\nFor more information see:\n\nHyndman, R.J. and Fan, Y., 1996. Sample quantiles in statistical packages. The American Statistician, 50(4), pp.361-365.\n\n\ny &lt;- c(98, 100, 100, 103, 105, 107, 110, 113, 115)\n\nquantile(y, 0.75, type = 6) - quantile(y, 0.25, type = 6) ## Type 6\n\n 75% \n11.5 \n\n## Default which we will generally use going forward\nquantile(y, 0.75) - quantile(y, 0.25) \n\n75% \n 10 \n\n\nPERCENTILES\nThe 5th and 95th percentiles cut off 5% of the most extreme values in the distribution of values for the sample. The 1st and 99th percentiles may be similarly defined. As with quartiles, a list of percentiles may be far more informative than the standard deviation for summarizing the spread of values about the mean or median, especially when the spread is asymmetrical.\nVARIANCE\nIn general, we have \\(n\\) observations, so the general formula for the sample variance is\n\\[s^2 = \\frac{1}{n-1}\\sum_{i=1}^{n} (y_i - \\bar{y})^2\\]\nThe units for the variance are always the units of the original measurement squared. If units of measurement were kg (e.g. body weight), then the variance would have units \\(kg^2\\).\nSTANDARD DEVIATION\nTo have a measure of variability with the same units as the original measurement, we take the square root of the variance. This is the standard deviation of the observations (usual symbol is s).\nSample standard deviation,\n\\[s = \\sqrt{\\frac{1}{n-1}\\sum_{i=1}^{n} (y_i - \\bar{y})^2}\\] DEGREES OF FREEDOM\nThe value n-1 in the above equations for variance and standard deviation is referred to as the degrees of freedom (df). Ashcroft & Pereira (2003) explain this concept in the following way.\n“The degrees of freedom in our analysis is the number of observations that are allowed to vary if our sample characteristic is to estimate precisely the population characteristic. For instance, when we are estimating just one population characteristic like the population variance and out sample size is n, the degrees of freedom is n-1 since control of just one observation (i.e. the rest are free to vary) is all that is required to make our sample variance exactly equal to the population variance.\nAs an example, suppose we have a sample of 5 observations \\((x_1, x_2, x_3, x_4, x_5; n=5)\\) from a population whose mean is 6. Observe in the table below how control of the last observation can make our sample mean exactly equal to the population mean of 6 when the first 4 observations are free to change their values.\n\n\n\nx1\nx2\nx3\nx4\n(Make x5)\nSample mean\n\n\n\n\n2\n4\n7\n8\n(9)\n6\n\n\n4\n6\n5\n7\n(8)\n6\n\n\n3\n7\n4\n9\n(7)\n6\n\n\n\nHere we see that a group of 5 observations being used to estimate a single population characteristic has 4 degrees of freedom. In general, when k population characteristics are being estimated from n observations, the degrees of freedom of the analysis is n-k.”\nCOEFFICIENT OF VARIATION\nThe coefficient of variation (CV) is used is used to aide in comparing the variability of two samples that have widely differing means. It is usually expressed as a percentage, and has no units.\n\\[CV = \\frac{s}{\\bar{y}} \\times 100\\%\\]",
    "crumbs": [
      "Describing data",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Exploratory Data Analysis EDA</span>"
    ]
  },
  {
    "objectID": "020-exploring_data.html#tabular-summaries",
    "href": "020-exploring_data.html#tabular-summaries",
    "title": "1  Exploratory Data Analysis EDA",
    "section": "1.2 Tabular Summaries",
    "text": "1.2 Tabular Summaries\n\n1.2.1 Tables of means\nTables are a way of organizing the data collected or providing a summary presentation of the data. The two most common types of tabular summaries you will encounter are tables of means and frequency tables.\nAn example of a table of means is the following table that shows the mean number of sedge plants, Carex flacca, found in 800 sample quadrats in an ecological study of grasses. Each quadrat was randomly assigned to one of four treatments: control, low, medium, and high. The table shows the mean number of sedge plants found in each treatment. We will simulate the data for this example.\n\nlibrary(dplyr)\nlibrary(kableExtra)\n\nset.seed(123) # For reproducibility\n\n# Simulate data\nquadrats &lt;- data.frame(\n  Treatment = factor(rep(c(\"Control\", \"Low\", \"Medium\", \"High\"), each = 200)),\n  SedgePlants = c(\n    rpois(200, lambda = 5),  # Assuming a Poisson distribution for count data \n    rpois(200, lambda = 10),\n    rpois(200, lambda = 15),\n    rpois(200, lambda = 20)\n  )\n)\n\nquadrats &lt;- quadrats %&gt;%\n  group_by(Treatment) %&gt;%\n  summarise(MeanSedgePlants = mean(SedgePlants))\nkable(quadrats)\n\n\n\n\nTreatment\nMeanSedgePlants\n\n\n\n\nControl\n5.060\n\n\nHigh\n20.050\n\n\nLow\n9.955\n\n\nMedium\n14.860\n\n\n\n\n\n\n\n1.2.2 Frequency Tables\nAn example of a tabular summary is the following table that shows the number of sedge plants, Carex flacca, found in 800 sample quadrats in an ecological study of grasses. Each quadra\nSedge plant data sourced from Glover & Mitchell (2002)\n\n\n\nPlants/quadrat \\((y_i)\\)\nFrequency \\((f_i)\\)\n\n\n\n\n0\n268\n\n\n1\n316\n\n\n2\n135\n\n\n3\n61\n\n\n4\n15\n\n\n5\n3\n\n\n6\n1\n\n\n7\n1\n\n\n\nThis table can be further organized into a relative frequency \\((f_i/n \\times 100)\\) table by expressing each row as a percentage of the total observation or into a cumulative frequency distribution by accumulating all observations up to and including each row i.e. \\(\\Sigma^r_{i=1}f_i\\) where \\(r\\) is the row number. The cumulative frequency distribution could be further manipulated into a relative cumulative frequency distribution by expressing each row of the cumulative frequency distributions as a percentage of the total i.e. \\(\\Sigma^r_{i=1}f_i/n \\times 100\\)",
    "crumbs": [
      "Describing data",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Exploratory Data Analysis EDA</span>"
    ]
  },
  {
    "objectID": "020-exploring_data.html#graphical-summaries",
    "href": "020-exploring_data.html#graphical-summaries",
    "title": "1  Exploratory Data Analysis EDA",
    "section": "1.3 Graphical Summaries",
    "text": "1.3 Graphical Summaries\n\n1.3.1 Bar Graphs and Histograms\nFrequency tabulations can be represented as a graph of frequency (raw or percentage) against the measurement variable. Discrete data are sometimes expressed as a bar graph where bars are spaced equidistantly along the horizontal axis. Figure 1.2 is a relative frequency histogram (also known as a percentage frequency histogram) of the sedge plant data. The data represents data from sedge plant counts in 800 1m x 1m quadrats Ideally this data set (since it is discrete) would be plotted as a bar graph.\n\nlibrary(tidyverse)\n\nsedge &lt;- read_csv(\"data/Sedge.csv\", show_col_types = FALSE)\n\nggplot(sedge, aes(x = Plants)) +\n  geom_histogram(aes(y = after_stat(count)/sum(after_stat(count)) * 100), bins = 8) +\n  ylab(\"Percentage\") +\n  xlab(\"Number of plants per quadrat\")\n\n\n\n\nFigure 1.2 Relative frequency histogram of sedge plant data.\n\n\n\n\nContinuous measurements are free to take any whole or fractional number within their range e.g. plant height, soil pH, concentration of nitrates in a water sample. Histograms (with bars touching each other) are the norm for continuous data.\n\nbentgrass &lt;- read_csv(\"data/Bentgrass.csv\", show_col_types = FALSE)\n\nggplot(bentgrass, aes(x = Root_length_mm)) +\n  geom_histogram(bins = 20) +\n  xlab(\"Root length (mm)\")\n\n\n\n\nFigure 1.3 Frequency histogram of creeping bentgrass data.\n\n\n\n\nA histogram can give nearly complete information about the distribution of data. For example, from Figure 1.3 above (that shows a fairly symmetric distribution) we can estimate that the mean ≈ 95 mm (the centre of the data) and standard deviation ≈ 15 mm (since for symmetric distributions approximately 95% of data lies within 2 standard deviations either side of the mean i.e. a total of 4 standard deviations across 95% of the data values).\nA histogram needs a relatively large sample size for it to be informative (i.e. 30 or more data values).\n\n\n1.3.2 Boxplots\nBoxplots show the shape of the distribution of data very clearly and are also helpful in identifying any outlying (or extreme) values.\nExample 1 Creeping bentgrass turf was laid in an experiment to assess root growth. Eighty (80) “plugs” were randomly sampled 4 weeks after laying. Root growth was measured by averaging the length (mm) of the ten longest roots in each plug.\n\nggplot(bentgrass, aes(x = Root_length_mm)) +\n  geom_boxplot() +\n  xlab(\"Root length (mm)\")\n\n\n\n\n\n\n\n\nNotes on boxplots:\n\n50% of the data are contained within the box (inter quartile range).\nWhiskers are extended to a maximum of 1.5 x IQR\nAny data values beyond these maximum whisker lengths are plotted individually, usually by an asterisk or dot \\(\\Rightarrow\\) these may be outliers and distort the results of any further analysis\nA boxplot gives useful summary of the shape of the data distribution e.g. Is it symmetric or skewed? Are there any outliers?\nBoxplots do not need as many data values (as some other graphs such as histograms and dot plots) for them to be informative.\n\nGUIDELINES FOR MAKING A BOXPLOT\nWe will use the gravimetric water content of soil (%) from Method A in the irrigation data set to illustrate how a boxplot is constructed. In this example we have n = 10 observations. We can use the R function, summary() to calculate some of the important values in a boxplot such as Q1, Q2, and Median.\n\nsoil_water &lt;- data.frame(water_content = c(7.5, 9.0, 9.3, 10.4, 10.4, 10.6, 10.7, 11.6, 12.1, 12.8))\n\nsummary(soil_water$water_content)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  7.500   9.575  10.500  10.440  11.375  12.800 \n\n\nStep 1: Determining the Box:\n\nThe quartiles (Q1: 1st Qu. & Q3: 3rd Qu.) then become the basis for the “box”\nThe median is shown as a vertical line through the box.\n\nStep 2: Determining (potential) outliers\n\nCalculate IQR = Inter-quartile range = 11.375 - 9.575 = 1.8\nCalculate Q1 - 1.5 x IQR = 9.225 - 1.5 x 1.8 = 6.875 Since there are no observations smaller than 6.875, there are no low-valued outliers.\nCalculate Q3 + 1.5 x IQR = 11.375 + 1.5 x 1.8 = 14.075 Since there are no observations greater than 14.075, there are no high-valued outliers.\nIf any values were flagged to be (potential) outliers, they are plotted as individual points on the boxplot, usually as a “*” or \\(\\bullet\\).\n\nStep 3: Determining the “whisker” lengths\n\nExtend the whisker from the lower end of the box (Q1) to the smallest value that is not an outlier, i.e. to the smallest value greater then Q1 - 1.5 x IQR. That is, the whisker here will be extended down to the minimum value which is 7.5.\nExtend the whisker from the upper end of the box (Q3) to the largest value that is not an outlier, i.e. to the greatest value smaller then Q3 + 1.5 x IQR. That is, the whisker here will be extended up to 12.8.\n\nUsing these values, the following boxplot is obtained:\n\nggplot(soil_water, aes(x = water_content)) +\n  geom_boxplot() +\n  xlab(\"gravimetric water content of soil (%)\")\n\n\n\n\n\n\n\n\n\n\n1.3.3 Scatterplots\nScatter plots are used to represent graphically the relationship between two variables. The extent and nature of the relationship between two (or more) variables is quantified through tools such as correlation and regression. This will be covered in later chapters.",
    "crumbs": [
      "Describing data",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Exploratory Data Analysis EDA</span>"
    ]
  },
  {
    "objectID": "020-exploring_data.html#shapes-of-distributions",
    "href": "020-exploring_data.html#shapes-of-distributions",
    "title": "1  Exploratory Data Analysis EDA",
    "section": "1.4 Shapes of Distributions",
    "text": "1.4 Shapes of Distributions\n\n1.4.1 Symmetric\nThis is a distribution such that the left hand side of the frequency polygon is a mirror image of the right hand side. For symmetrical distributions, the mean, median and mode all have the same value. Substantial differences in these three statistics could provide valuable information about the data set (as we’ll see in the sections on positively and negatively skewed distributions). Some examples of symmetric distributions appear below.\n\n\n\nFigure 1.4 Four examples of symmetric distributions.\n\n\nExample: Creeping bentgrass: root growth (mm)\n\nsummary(bentgrass)\n\n Root_length_mm  \n Min.   : 65.00  \n 1st Qu.: 86.75  \n Median : 93.00  \n Mean   : 93.86  \n 3rd Qu.:102.00  \n Max.   :135.00  \n\n\nNote that the mean and the median are similar (93.9, and 93.0 mm respectively). This is indicative of symmetric data. The boxplot and histogram below show that the data is symmetric about the mean. You will notice from the boxplot that there is one high value outlier indicated by the “x” at the right hand side of the graph. The “4” indicates that this is the 4th observation in the data set i.e. the value 135 mm.\n\nlibrary(patchwork)\np1 &lt;- ggplot(bentgrass, aes(x = Root_length_mm)) +\n  geom_boxplot() +\n  xlab(\"Root length (mm)\")\np2 &lt;- ggplot(bentgrass, aes(x = Root_length_mm)) +\n  geom_histogram(bins = 20) +\n  xlab(\"Root length (mm)\")\np1+p2\n\n\n\n\nFigure 1.5 Boxplot (left) and histogram (right) of the creeping bentgrass data show symmetry.\n\n\n\n\n\n\n1.4.2 Positively Skewed\nFor right-skewed distributions we find that the mode (if one exists) is always less than the median and the median is always less than the mean. Example: As part of an evaluation of a clean-up of a contaminated site, 100 soil samples were taken randomly across an area and the level of 1,2,3,4 Tetrachlorobenzene was recorded in parts per billion (TcCB, ppb).\nThe following descriptive analysis was undertaken.\n\ntccb &lt;- read_csv(\"data/TcCB.csv\", show_col_types = FALSE)\n\nsummary(tccb)\n\n    TcCB_ppb     \n Min.   : 0.010  \n 1st Qu.: 0.235  \n Median : 0.570  \n Mean   : 1.412  \n 3rd Qu.: 1.292  \n Max.   :26.600  \n\n\n\np1 &lt;- ggplot(tccb, aes(x = TcCB_ppb)) +\n  geom_boxplot() +\n  xlab(\"TcCB concentration (ppb)\")\np2 &lt;- ggplot(tccb, aes(x = TcCB_ppb)) +\n  geom_histogram(bins = 20) +\n  xlab(\"TcCB concentration (ppb)\")\np1+p2\n\n\n\n\nFigure 1.6 Boxplot (left) and histogram (right) of the TcCB data showing positive skewness.\n\n\n\n\nThe distribution is highly positively skewed (right skewed): there are extreme outliers at high levels. This is also demonstrated by the mean (1.412 ppb) being substantially greater than the median (0.570 ppb).\n\n\n1.4.3 Negatively Skewed\nFor left-skewed distributions we find that the mode is greater than the median and the median is greater than the mean.\nExample: - The age of onset of osteoarthritis was recorded in 13 dogs. - The majority of the values cluster around the 10-13 age range, which represents the more common onset age for the chronic condition in older dogs. - There are also some lower values representing the less common earlier onset of the condition.\n\narthritis &lt;- read_csv(\"data/Arthritis.csv\", show_col_types = FALSE)\n\nsummary(arthritis)\n\n   AgeAtOnset    \n Min.   : 3.800  \n 1st Qu.: 7.225  \n Median :11.150  \n Mean   : 9.714  \n 3rd Qu.:12.000  \n Max.   :13.200  \n\n\n\np1 &lt;- ggplot(arthritis, aes(x = AgeAtOnset)) +\n  geom_boxplot() +\n  xlab(\"Age at onset (years)\")\np2 &lt;- ggplot(arthritis, aes(x = AgeAtOnset)) +\n  geom_histogram(bins = 5) +\n  xlab(\"Age at onset (years)\")\np1+p2\n\n\n\n\nFigure 1.7 Boxplot (left) and histogram (right) of the river pollution data showing negative skewness.\n\n\n\n\nThe distribution is negatively skewed (left skewed): there are some outliers at low levels. This is also demonstrated by the mean (9.7 years) being marginally less than the median (11.1 years).\n\n\n1.4.4 Statistics of Shape\nThere are two statistics useful for describing shape.\nSKEWNESS\nSkewness is another name for asymmetry which means that one tail of the frequency distribution is drawn out more than the other. A skewness of zero implies a symmetrically shaped histogram, a negative value implies skewness to the left and a positive value implies skewness to the right.\n\nlibrary(moments)\nskewness(bentgrass)\n\nRoot_length_mm \n    0.08475045 \n\nskewness(tccb)\n\nTcCB_ppb \n5.998866 \n\nskewness(arthritis)\n\nAgeAtOnset \n-0.8257301 \n\n\nKURTOSIS\nKurtosis is a measure of how “peaked” (leptokurtic) a frequency distribution is or how “flattened” (platykurtic) it is. A negative value indicates platykurtosis (or flatness), and a positive value indicates leptokurtosis (peakedness).\n\nkurtosis(bentgrass)\n\nRoot_length_mm \n      3.354701 \n\nkurtosis(tccb)\n\nTcCB_ppb \n46.11769 \n\nkurtosis(arthritis)\n\nAgeAtOnset \n  2.030982 \n\n\nBIMODAL\nNote: Bimodal distributions expected indicate a mixture of samples from two populations (e.g. weights of male and females). While the mode is not often used in biological research, reporting the number of modes, if more than one, can be informative.",
    "crumbs": [
      "Describing data",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Exploratory Data Analysis EDA</span>"
    ]
  },
  {
    "objectID": "020-exploring_data.html#normality-versus-non-normality-in-the-descriptive-statistics-context",
    "href": "020-exploring_data.html#normality-versus-non-normality-in-the-descriptive-statistics-context",
    "title": "1  Exploratory Data Analysis EDA",
    "section": "1.5 Normality versus Non-Normality (in the Descriptive Statistics Context)",
    "text": "1.5 Normality versus Non-Normality (in the Descriptive Statistics Context)\n\n1.5.1 Normality\nMost natural groups of objects show variation. Humans differ in height, even if of the same sex, race and age. In many instances, measurements of similar objects vary about their mean according to a well-defined function, the normal or Gaussian distribution function.\nThe normal distribution has the following characteristics:\n\nIt is symmetric about its mean, median and mode. Hence a normal distribution has a skewness of zero.\nIt is bell-shaped, with a kurtosis of zero (recall kurtosis is “flatness”).\nIt is a continuous curve defined for values from minus infinity to plus infinity.\nIt is completely defined by its mean and standard deviation. That is, if you know the mean and standard deviation of the normal curve, you can calculate its exact equation.\nPDF for normal distribution: \\(f(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}\\)\n95% of observations fall in the range defined by the mean plus or minus 1.96 standard deviations and 99% fall in the range defined by the mean plus or minus 2.58 standard deviations.\n\nSummary statistics for a sample drawn from a normally distributed population would usually include the range of values encountered, the arithmetic mean, the standard deviation and the size of the sample from which these statistics were calculated. All other information, including the frequency tabulation, the mode, median, percentiles, sample skewness and kurtosis would be superfluous.\nWe will look at the normal distribution in detail later in this section.\n\n\n1.5.2 Non-Normality\nFor data that do not conform to the theoretical normal distribution, the situation is more complex. No longer will the mean and standard deviation suffice in order to reconstruct the frequency distribution of the raw data. No longer would we expect only 5% of values to lie outside the mean plus or minus 1.96 standard deviations. A more detailed description of the characteristics of non-normal data is required.\nSubstantial differences between the model, median and arithmetic mean are apparent when a skewed distribution is considered. Clearly the three averages can have distinctly different values. Which is the most appropriate average? The mean is markedly affected by outlying observations whereas the median and mode are not.\nThe difference between the mean and median has important practical consequences for analysis of data that contains aberrant outlying values (perhaps because of errors at the time of measurement or during transcription in preparing the data). Such errors, if they go unnoticed, can seriously affect an analysis.\nMost modern statistical packages perform various tests to determine if your data are likely to have been drawn from a normally distributed population. We’ll look at these later.",
    "crumbs": [
      "Describing data",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Exploratory Data Analysis EDA</span>"
    ]
  },
  {
    "objectID": "021-probability_distributions.html",
    "href": "021-probability_distributions.html",
    "title": "2  Probability distributions",
    "section": "",
    "text": "2.1 Probability\nSimple Probability\nProbability of an event occurring:\n\\(P(E)=\\frac{\\text{Number of ways an event can occur}}{\\text{Total number of possible outcomes}}\\)\nExample: A person is chosen at random to write about his/her favourite sport. Thirty-five people like tennis, 51 like cricket, 17 like squash, 23 like baseball and 62 like swimming. Find the probability that the article will be about:\nComplementary Events\nProbability of an event not occurring = 1 – probability of event occurring.\n\\(P(E) =1− P(E)\\)\nExercises\nNon-Mutually Exclusive Events\nNon-mutually exclusive events have some overlap - more than one thing can happen at the same time.\n\\(P(A \\text{ or } B) = P(A) + P(B) – P(A \\text{ and } B)\\)\nExercise\nProduct Rule\nWhen we do more than one thing (e.g. toss 2 coins, plant 5 seeds, choose 3 people, throw 2 dice) we multiply the probabilities together.\n\\(P(A and B) = P(A).P(B)\\)\nExercises",
    "crumbs": [
      "Describing data",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Probability distributions</span>"
    ]
  },
  {
    "objectID": "021-probability_distributions.html#probability",
    "href": "021-probability_distributions.html#probability",
    "title": "2  Probability distributions",
    "section": "",
    "text": "\\(P(E) = 0\\) the event is impossible\n\\(P(E) = 1\\) the event is certain (must happen)\n\n\n\nswimming: \\(\\frac{62}{188}=\\frac{31}{94}\\)\nsquash or tennis: \\(\\frac{17+35}{188}=\\frac{52}{188}=\\frac{13}{47}\\)\n\n\n\n\n\n\nThe probability of rain on the 23rd January each year is \\(\\frac{17}{53}\\). What is the probability of no rain on the 23rd January 2007?\nThe probability of a seed producing a red flower is \\(\\frac{7}{8}\\). Find the probability of the flower producing a different colour.\n\n\n\n\n\n\nIn a group of 20 people, 14 like to watch the news on television and 17 like to watch old movies. Everyone watches one or the other or both. If I choose one person at random, find the probability that the person likes watching:\n\n\nBoth the news and the old movies;\nOnly the news.\n\n\n\n\n\n\nA box contains 3 black pens, 4 red pens, and 2 green pens. If I draw out 2 pens at random, find the probability that they are both red.\nThe probability of a seed germinating is 0.91. If I plant 5 seeds, find the probability that they all germinate.",
    "crumbs": [
      "Describing data",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Probability distributions</span>"
    ]
  },
  {
    "objectID": "021-probability_distributions.html#probability-density-functions",
    "href": "021-probability_distributions.html#probability-density-functions",
    "title": "2  Probability distributions",
    "section": "2.2 Probability Density Functions",
    "text": "2.2 Probability Density Functions\nProbability density functions (PDFs) are a way of mathematically describing the shape of distributions. Examples:\nBinomial: \\(P(X = k) = \\binom{n}{k} p^k (1-p)^{n-k}\\)\nPoisson: \\(P(X=k) = \\frac{\\lambda^k e^{-\\lambda}}{k!}\\)\nNormal: \\(f(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}}e^{-\\frac{1}{2}\\left(\\frac{x-\\mu}{\\sigma}\\right)^2}\\)\nFor continuous distributions we define the area under the curve as the probability. This area is equal to 1 or 100%.",
    "crumbs": [
      "Describing data",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Probability distributions</span>"
    ]
  },
  {
    "objectID": "021-probability_distributions.html#types-of-distributions",
    "href": "021-probability_distributions.html#types-of-distributions",
    "title": "2  Probability distributions",
    "section": "2.3 Types of distributions",
    "text": "2.3 Types of distributions\nJust as there are different types of data (continuous, discrete etc.), there are different types of statistical distributions. Statistical distributions are generally categorized as either continuous e.g. normal distribution, or discrete e.g. binomial distribution. In this unit of study we will only consider continuous distributions.",
    "crumbs": [
      "Describing data",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Probability distributions</span>"
    ]
  },
  {
    "objectID": "021-probability_distributions.html#probability-for-continuous-distributions",
    "href": "021-probability_distributions.html#probability-for-continuous-distributions",
    "title": "2  Probability distributions",
    "section": "2.4 Probability for Continuous Distributions",
    "text": "2.4 Probability for Continuous Distributions\nFor discrete variables, it makes sense to talk about the probability of a specific outcome occurring, e.g. the probability of exactly three insects caught. However, for continuous variables, this is more problematic.\nExample:\nConsider the gestational period of cattle measured in days. What is the probability that it is exactly 295 days long? We don’t mean in the range 295-296 days, or 294.9999 to 295.0001 days, but exactly 295 days. Clearly, this probability must be infinitesimally small - effectively zero!\nThe way around this is to talk about the probability of getting a value within a range. For example, if Y represents gestational length, we might want the probability that it is between 285 and 305 days long, \\(P(285 \\le Y \\le 305)\\), or at least 295 days long, \\(P(Y \\ge 295)\\).\nWe summarise the probability distribution of a statistical distribution by means of a probability density function (PDF), which we graph against the outcome, Y. The PDF for gestational length might show the shape below.\n\nlibrary(ggplot2)\n# Define the mean and standard deviation\nmean &lt;- 284.3\nsd &lt;- 5.52\n# Create a sequence of x values\nx_values &lt;- seq(mean - 4*sd, mean + 4*sd, length.out = 1000)\n# Create a ggplot\nggplot(data.frame(x_values), aes(x = x_values)) +\n  stat_function(fun = dnorm, args = list(mean = mean, sd = sd)) +\n  labs(title = \"PDF\", x = \"Gestation Period (days)\", y = \"Density\") +\n  theme_minimal()\n\n\n\n\nFigure 3.1 The symmetric bell shaped distribution – just one distribution in the family of continuous distributions.\n\n\n\n\nWe interpret the area under the curve as the probability. Further, the total area under a curve is 1. For example, the probability of sampling a gestational length of between 285 and 305 days, \\(P(285 ≤ Y ≤ 300)\\) is:\n\n# Load the ggplot2 library\nlibrary(ggplot2)\n\n# Define the mean and standard deviation\nmean &lt;- 284.3\nsd &lt;- 5.52\n\n# Define the range for the shaded area\nlower_bound &lt;- 285\nupper_bound &lt;- 300\n\n# Create a data frame for the x values\nx_values &lt;- seq(mean - 4*sd, mean + 4*sd, length.out = 1000)\ndf &lt;- data.frame(x = x_values)\n\n# Create the ggplot object\nggplot(df, aes(x)) +\n  stat_function(fun = dnorm, args = list(mean = mean, sd = sd), colour = \"blue\") +\n  geom_area(stat = \"function\", fun = dnorm, args = list(mean = mean, sd = sd),\n            xlim = c(lower_bound, upper_bound), fill = \"blue\", alpha = 0.2) +\n  labs(title = \"PDF\", x = \"Value\", y = \"Density\") +\n  theme_minimal()\n\n\n\n\nFigure 3.2 The shaded area under the PDF curve for a normal distribution is interpreted as the probability of a value occurring within a defined range.\n\n\n\n\nThere are other continuous distributions other than the commonly cited normal distribution. The continuous distributions you are likely to encounter during your undergraduate degree are: normal, student’s T, chi square, F, log normal, exponential, gamma.\nHighlighting just one of these… If a variable \\(\\log{y} = y'\\) has a normal \\(N(\\mu,\\sigma^2)\\) distribution, then the original variable has a log normal distribution.\n\nlibrary(ggplot2)\n\n# Data for standard normal distribution\nx_norm &lt;- seq(-5, 5, length.out = 1000)\ny_norm &lt;- dnorm(x_norm)\n\n# Data for log-normal distribution\nx_lognorm &lt;- seq(0.01, 3, length.out = 1000) # Avoid starting at 0 to prevent log(0)\ny_lognorm &lt;- dlnorm(x_lognorm)\n\n# Data frame for standard normal\ndf_norm &lt;- data.frame(x = x_norm, y = y_norm, Distribution = 'Standard Normal')\n\n# Data frame for log-normal\ndf_lognorm &lt;- data.frame(x = x_lognorm, y = y_lognorm, Distribution = 'Log-Normal')\n\n# Combine data frames\ndf &lt;- rbind(df_norm, df_lognorm)\n\n# Plot\nggplot(df, aes(x = x, y = y, color = Distribution)) + \n  geom_line() + \n  facet_wrap(~Distribution, scales = 'free_x') + \n  theme_minimal() + \n  labs(title = \"Log-Normal PDF vs. Normal PDF\", \n       x = \"Value\", \n       y = \"Density\")\n\n\n\n\nThe normal and log normal distributions",
    "crumbs": [
      "Describing data",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Probability distributions</span>"
    ]
  },
  {
    "objectID": "021-probability_distributions.html#the-normal-distribution",
    "href": "021-probability_distributions.html#the-normal-distribution",
    "title": "2  Probability distributions",
    "section": "2.5 The Normal Distribution",
    "text": "2.5 The Normal Distribution\nWe began speaking about the normal distribution in Section 2.5.1. Recall that it is also sometimes referred to as the Gaussian distribution (named after a man who contributed significantly to this area of mathematics). This is the “bell-shaped” distribution commonly observed in histograms of biological and environmental data e.g. height, weight, gestation lengths, etc. It is central to most statistical theory.\n The centre of the curve is located at μ and σ indicates the spread or width of the curve. For all distributions, a type of shorthand has been introduced to denote the name of the distribution that a particular variable, \\(y\\), follows. For example, you should read the abbreviation \\(y \\sim N(\\mu,\\sigma^2)\\) as ’the variable \\(y\\) is normally distributed with mean \\(\\mu\\) and variance \\(\\sigma^2\\).\nAs we will discover later, for data that follows a normal distribution we expect that 95% of observations fall in the range defined by the mean plus or minus 1.96 standard deviations and 99% fall in the range defined by the mean plus or minus 2.58 standard deviations. This is the basis for the following approximations (that you may already be familiar with):\n\n68% of data lie within \\(\\pm 1 \\sigma \\text{ of } \\mu\\)\n95% of data lie within \\(\\pm 2 \\sigma \\text{ of } \\mu\\)\n\nRecall that if you know the mean and standard deviation of the normal curve, you can calculate its exact equation.\nPDF for normal distribution: \\(f(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}}e^{-\\frac{1}{2}\\left(\\frac{x-\\mu}{\\sigma}\\right)^2}\\)\nwhere \\(\\sigma\\) is the population standard deviation and \\(\\mu\\) is the population mean.\nThe \\(N(0,1)\\) distribution \\((\\mu = 0, \\sigma^2 = 1)\\) is called the standard normal distribution, usually termed \\(Z\\), i.e. \\(Z \\sim N(0,1)\\). Probability tables (including standard normal probability tables) are published in most statistical texts. They show the proportions of data found below a value in the distribution. For the normal distribution, only probabilities for the \\(N(0,1)\\) distribution are tabulated. For other normal distributions e.g. \\(N(20,5)\\) the probabilities are obtained by calculating the standardised value:\n\\(Z=\\frac{y-\\mu}{\\sigma}\\)\nIf we substitute \\(\\sigma = 1\\) and \\(\\mu = 0\\) into the PDF for the normal, we find that the PDF for the standard normal distribution is\n\\(f(z)=\\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{1}{2}z^2}\\)\n\n2.5.1 Calculating Probabilities for Standardised Normal Values\nTo calculate probabilities in the standardised normal distribution, remember that the values given in the CDF are cumulative probabilities - i.e. probabilities of values of z occurring below a particular value. For example, looking at the pnorm(0) we see the probability associated with a Z value of 0 is 0.5. This means that half the values are below 0 (i.e. 50%). Using R - if we want to know what the probability of obtaining a value greater than the point of interest, then we subtract probability of obtaining a value less than point of interest from 1 (the total area under the curve). To find the probability of a value occurring between two points, subtract the probability of being less than the lower value from the probability of being less than the upper value. The easiest way to understand this is to draw the curve showing the area required, as in the figures below.\n\npnorm(0)\n\n[1] 0.5\n\n\n\n\n\nStandardized Normal Values\n\n\nExamples\n\n\n\n\\(P(Z &lt; 1.85)\\) where \\(Z \\sim N(0, 1)\\)\n\\(P(Z &lt; 1.85) = 0.9678\\)\n\npnorm(1.85)\n\n[1] 0.9678432\n\n\n\n# Load the ggplot2 library\nlibrary(ggplot2)\n\n# Define the mean and standard deviation\nmean &lt;- 0\nsd &lt;- 1\n\n# Define the range for the shaded area\nlower_bound &lt;- -4\nupper_bound &lt;- 1.85\n\n# Create a data frame for the x values\nx_values &lt;- seq(mean - 4*sd, mean + 4*sd, length.out = 1000)\ndf &lt;- data.frame(x = x_values)\n\n# Create the ggplot object\nggplot(df, aes(x)) +\n  stat_function(fun = dnorm, args = list(mean = mean, sd = sd), colour = \"blue\") +\n  geom_area(stat = \"function\", fun = dnorm, args = list(mean = mean, sd = sd),\n            xlim = c(lower_bound, upper_bound), fill = \"blue\", alpha = 0.2) +\n  labs(title = \"PDF\", x = \"Value\", y = \"Density\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\\(P(Z &gt; 1.85)\\) where \\(Z \\sim N(0, 1)\\)\n\\(1 - P(Z &lt; 1.85) = 0.0322\\)\n\n1-pnorm(1.85)\n\n[1] 0.03215677\n\n\n\n# Load the ggplot2 library\nlibrary(ggplot2)\n\n# Define the mean and standard deviation\nmean &lt;- 0\nsd &lt;- 1\n\n# Define the range for the shaded area\nlower_bound &lt;- 1.85\nupper_bound &lt;- 4\n\n# Create a data frame for the x values\nx_values &lt;- seq(mean - 4*sd, mean + 4*sd, length.out = 1000)\ndf &lt;- data.frame(x = x_values)\n\n# Create the ggplot object\nggplot(df, aes(x)) +\n  stat_function(fun = dnorm, args = list(mean = mean, sd = sd), colour = \"blue\") +\n  geom_area(stat = \"function\", fun = dnorm, args = list(mean = mean, sd = sd),\n            xlim = c(lower_bound, upper_bound), fill = \"blue\", alpha = 0.2) +\n  labs(title = \"PDF\", x = \"Value\", y = \"Density\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\\(P(–1 &lt; Z &lt; 2)\\) where \\(Z \\sim N(0, 1)\\)\n\\(P(Z &lt; 2)  \\approx  0.9772\\) (from R)\n\\(P(Z&lt; –1) \\approx  0.1587\\) (from R)\n\\(P(–1 &lt; Z &lt; 2) \\approx  0.9772 – 0.1587 \\approx  0.8185\\)\n\npnorm(2)\n\n[1] 0.9772499\n\npnorm(-1)\n\n[1] 0.1586553\n\npnorm(2) - pnorm(-1)\n\n[1] 0.8185946\n\n\n\n# Load the ggplot2 library\nlibrary(ggplot2)\n\n# Define the mean and standard deviation\nmean &lt;- 0\nsd &lt;- 1\n\n# Define the range for the shaded area\nlower_bound &lt;- -1\nupper_bound &lt;- 2\n\n# Create a data frame for the x values\nx_values &lt;- seq(mean - 4*sd, mean + 4*sd, length.out = 1000)\ndf &lt;- data.frame(x = x_values)\n\n# Create the ggplot object\nggplot(df, aes(x)) +\n  stat_function(fun = dnorm, args = list(mean = mean, sd = sd), colour = \"blue\") +\n  geom_area(stat = \"function\", fun = dnorm, args = list(mean = mean, sd = sd),\n            xlim = c(lower_bound, upper_bound), fill = \"blue\", alpha = 0.2) +\n  labs(title = \"PDF\", x = \"Value\", y = \"Density\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n2.5.2 Calculating Probabilities for Non-Standardised Normal Values\nSuppose that from long term studies, it is known that the gestation length of cattle (in days) is normally distributed with a mean of 285 days and a standard deviation of 10 days i.e. \\(y \\sim N(285, 10^2)\\). The following is a plot of the theoretical distribution (PDF).\n\nlibrary(ggplot2)\n# Define the mean and standard deviation\nmean &lt;- 285\nsd &lt;- 10\n# Create a sequence of x values\nx_values &lt;- seq(mean - 4*sd, mean + 4*sd, length.out = 1000)\n# Create a ggplot\nggplot(data.frame(x_values), aes(x = x_values)) +\n  stat_function(fun = dnorm, args = list(mean = mean, sd = sd)) +\n  labs(title = \"PDF\", x = \"Gestation Period (days)\", y = \"Density\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nApproximately 68% of data lie within \\(\\pm 1 \\sigma\\) of \\(\\mu\\), i.e., \\(285 \\pm 10 =\\) \\(275\\) to \\(295\\) days. So if a pregnancy is selected at random, there is a probability of approximately 0.68 that it is between 275 days and 295 days in duration.\nApproximately 95% of data lie within \\(\\pm 2 \\sigma\\) of \\(\\mu\\), i.e., \\(285 \\pm 10 =\\) \\(265\\) to \\(305\\) days. So if a pregnancy is selected at random, there is a probability of approximately 0.95 that it is between 265 and 305 days in duration.\n\n# Load the ggplot2 library\nlibrary(ggplot2)\n\n# Define the mean and standard deviation\nmean &lt;- 285\nsd &lt;- 10\n\n# Define the range for the shaded area\nlower_bound &lt;- 275\nupper_bound &lt;- 295\n\n# Create a data frame for the x values\nx_values &lt;- seq(mean - 4*sd, mean + 4*sd, length.out = 1000)\ndf &lt;- data.frame(x = x_values)\n\n# Create the ggplot object\nggplot(df, aes(x)) +\n  stat_function(fun = dnorm, args = list(mean = mean, sd = sd), colour = \"blue\") +\n  geom_area(stat = \"function\", fun = dnorm, args = list(mean = mean, sd = sd),\n            xlim = c(lower_bound, upper_bound), fill = \"blue\", alpha = 0.2) +\n  labs(title = \"PDF\", x = \"Value\", y = \"Density\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n# Load the ggplot2 library\nlibrary(ggplot2)\n\n# Define the mean and standard deviation\nmean &lt;- 285\nsd &lt;- 10\n\n# Define the range for the shaded area\nlower_bound &lt;- 265\nupper_bound &lt;- 305\n\n# Create a data frame for the x values\nx_values &lt;- seq(mean - 4*sd, mean + 4*sd, length.out = 1000)\ndf &lt;- data.frame(x = x_values)\n\n# Create the ggplot object\nggplot(df, aes(x)) +\n  stat_function(fun = dnorm, args = list(mean = mean, sd = sd), colour = \"blue\") +\n  geom_area(stat = \"function\", fun = dnorm, args = list(mean = mean, sd = sd),\n            xlim = c(lower_bound, upper_bound), fill = \"blue\", alpha = 0.2) +\n  labs(title = \"PDF\", x = \"Value\", y = \"Density\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n2.5.3 Calculating Probabilities for Non-Standardised Normal Values\nExamples\n\n\n\nAssume that cabbage yields are known to be normally distributed with a mean \\(\\mu = 1.4\\) kg / plant, and a standard deviation \\(\\sigma = 0.2\\) kg / plant.\nFind \\(P(Y &lt; 1)\\) where we assume that \\(Y \\sim N(1.4, 0.2^2)\\).\n\npnorm(1, mean = 1.4, sd = 0.2)\n\n[1] 0.02275013\n\n\n\n\n\nFind the 5th and 95th percentile of cabbage yield Y, where we assume that \\(Y \\sim N(1.4, 0.2^2)\\).\nNow we are looking for the points on the x-axis given the probability (rather than finding a probability as we have to date).\nWe can use the qnorm function to find the quantiles.\n\nqnorm(0.05, mean = 1.4, sd = 0.2) # 5th percentile\n\n[1] 1.071029\n\n\n\nqnorm(0.95, mean = 1.4, sd = 0.2) # 95th percentile\n\n[1] 1.728971\n\n\n\n\n2.5.4 Exploring the Properties of the Normal Distribution - fun with Excel\n\nThere a many examples above of using ggplot to draw the normal distribution. However, you can also use Excel to draw the normal distribution. This is a useful skill to have as you can use Excel to draw the normal distribution for any mean and standard deviation, not just the standard normal distribution.\nPlotting the standard normal density function in Excel\nRecall that the probability density function (PDF) for the normal distribution is\n\n\\(f(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}}e^{-\\frac{1}{2}\\left(\\frac{x-\\mu}{\\sigma}\\right)^2}\\)\n\nFor the case of the standard normal distribution \\(Z \\sim N(0,1)\\) the formula becomes\n\n\\(f(z) = \\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{1}{2}z^2}\\)\n\nWe will evaluate this function over the range -3 &lt; Z &lt; 3. That is, we will substitute various values of z (between -3 and +3 in steps of 0.1) into the formula above to obtain their corresponding probability densities.\nOnce we’ve obtained these probabilities we’ll plot them on the y-axis and the z values on the x-axis to create our own bell-shaped normal curve in Excel.\n\nInstructions:\n\nIn cells A1:C1 type the following column headings: ‘z’; ‘PDF via formula’; ‘PDF via NORMDIST’.\nIn cells A2:A62 create a column of z values than range from -3 to +3 in incremental steps of 0.1. Type -3 in A2 and -2.9 in A3, highlight both cells and drag down with the black cross which should appear once you put the cursor near the bottom right hand corner.\n\nNow we’re going to obtain the corresponding probabilities in 2 different ways – you should get exactly the same answers.\n\nIn cell B2, enter the formula for the standard normal distribution using a cell references for z. Pick up the + at the bottom right hand corner and drag the mouse (left hand button) to drag this formula down the column to obtain the rest of the answers. You don’t need to re-enter the formula in each row.\nSome Excel functions for entering the formula are\n\n\n\n\nMathematical symbol/function\nExcel function\n\n\n\n\ne2\n=EXP(2)\n\n\n\\(\\pi\\)\n=PI()\n\n\n\\(\\sqrt{4}\\)\n=SQRT(4)\n\n\n\\(2^2\\)\n=2^2\n\n\n\n\nIn cell C2, insert the Excel function NORM.DIST and fill in the arguments [Remember the standard normal density function has a mean of 0 and variance of 1]. There is another shortcut method to apply this formula for Z from -3 to +3 in one step. Point the mouse to the bottom right hand corner of C2; the mouse will change shape to +; then simply double click on the + and the formula will automatically be filled down to as many cells as are not empty alongside.\nTidy up the formatting of your spreadsheet by centering columns and individual cells, and bolding important labels.\nUse the menus to plot the standard normal distribution, Insert &gt; Scatter &gt; Scatter with Smooth Lines. The screenshot below should help you.\n\n\n\n\nExcel\n\n\nConsider how you might do the above exercise for a non-standard normal distribution…\n\n\n2.5.5 Normality Tests\nNormality tests are the first introduction you’ll have to formal statistical hypothesis testing!\nFor every hypothesis test you (or the computer) need to perform the following steps (as a minimum):\n\nSet null & alternate hypotheses;\nCalculate test statistic;\nObtain P-value and or critical value;\nDraw a conclusion about your null hypothesis from the P-value (or by comparing the test statistic with the critical value).\n\nWe’ll expand these steps soon…\nThere are quite a few normality tests that statisticians have developed over the years. We will focus on one of these. The Shapiro-Wilk test is a test of the null hypothesis that the data is normally distributed. The test statistic is calculated using the data and then using this test statistic, a probability value (P-value) is obtained. From the P-value we make a decision whether or not to reject the null hypothesis (i.e. whether or not to reject the normality assumption).\nWe will be using tetrachlorobenzene levels (TcCB, ppb) in 100 soil samples as our example data set to show how R performs the test. We have seen previously that the distribution of this data is HIGHLY POSITIVELY skewed.\n\n# Load the data\nTcCB &lt;- read.csv(\"data/TcCB.csv\")\n\n# Perform the Shapiro-Wilk test\nshapiro.test(TcCB$TcCB)\n\n\n    Shapiro-Wilk normality test\n\ndata:  TcCB$TcCB\nW = 0.40034, p-value &lt; 2.2e-16\n\n\nThe null hypothesis is that the data is normally distributed. The P-value is 0.0001, which is less than 0.05. Therefore, we reject the null hypothesis and conclude that the data is not normally distributed.",
    "crumbs": [
      "Describing data",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Probability distributions</span>"
    ]
  },
  {
    "objectID": "022-sampling_distributions.html",
    "href": "022-sampling_distributions.html",
    "title": "3  Sampling distributions",
    "section": "",
    "text": "3.1 The Central Limit Theorem\nThe Central Limit Theorem states that if a sample of size n is drawn from a population with mean \\(\\mu\\) and variance \\(\\sigma^2\\), then the distribution of the sample mean, \\(\\bar y\\), tends to the normal distribution as \\(n\\) increases, with mean \\(\\mu\\) and variance \\(\\sigma^2/n\\).\nILLUSTRATION of the Central Limit Theorem using Weights of 144 carrots (grams) in an arbitrary order [p. 23 Mead et al. (1993)]\nlibrary(ggplot2)\ncarrots &lt;- read.csv(\"data/Carrot_weights.csv\")\n\nmean(carrots$Weight_g)\n\n[1] 301.8958\n\nsd(carrots$Weight_g)\n\n[1] 221.3131\n\nggplot(carrots, aes(x=Weight_g)) + \n  geom_histogram(binwidth = 20, fill = \"lightblue\", color = \"black\") + \n  theme_minimal()\nset.seed(1)\nn &lt;- 4\nn_samples &lt;- 50\nsample_means &lt;- rep(NA, n_samples)\nfor (i in 1:n_samples) {\n  sample_means[i] &lt;- mean(sample(carrots$Weight_g, n))\n}\n\nmean(sample_means)\n\n[1] 301.435\n\nsd(sample_means)\n\n[1] 104.5059\n\nggplot() + \n  geom_histogram(aes(x=sample_means), binwidth = 20, fill = \"lightblue\", color = \"black\") + \n  theme_minimal()\nFor this column of means, the mean = 301.435g and the standard deviation = 104.506g.\nNOTE The standard deviation here is actually the standard error (see earlier section in these notes).\nset.seed(1)\nn &lt;- 16\nn_samples &lt;- 50\nsample_means &lt;- rep(NA, n_samples)\nfor (i in 1:n_samples) {\n  sample_means[i] &lt;- mean(sample(carrots$Weight_g, n))\n}\n\nmean(sample_means)\n\n[1] 300.7962\n\nsd(sample_means)\n\n[1] 43.70914\n\nggplot() + \n  geom_histogram(aes(x=sample_means), binwidth = 20, fill = \"lightblue\", color = \"black\") + \n  theme_minimal()\nFor this column of means (where n = 16), the mean = 300.796g and the standard deviation = 43.709g.\nThe means of our set of samples are of course not equal to the mean of the 144 individual observations but from our mathematical result that the variance of the distribution of means of sample of \\(n\\) observations is \\(\\sigma^2/n\\), we would expect the variance of the three distributions to be \\(\\sigma^2\\), \\(\\sigma^2/4\\) and \\(\\sigma^2/16\\), so that the standard deviations should be \\(\\sigma\\), \\(\\sigma/2\\) and \\(\\sigma/4\\) respectively. Do our estimated values agree tolerably with this expectation?",
    "crumbs": [
      "Describing data",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Sampling distributions</span>"
    ]
  },
  {
    "objectID": "022-sampling_distributions.html#the-central-limit-theorem",
    "href": "022-sampling_distributions.html#the-central-limit-theorem",
    "title": "3  Sampling distributions",
    "section": "",
    "text": "Create a histogram of the individual weights (see below). Obviously the distribution is not normal.\n\n\n\nFor these individual observations, mean = 301.896g and standard deviation = 221.313g.\nTake 50 random samples each of 4 weights; then average each of these 50 samples. Generate another histogram of these means (where n = 4). How would you compare this to the histogram of the original weights?\n\n\n\n\n\nRepeat the process, but now with n = 16. How would you compare this to the histogram of the original weights?",
    "crumbs": [
      "Describing data",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Sampling distributions</span>"
    ]
  },
  {
    "objectID": "030-ttest1.html",
    "href": "030-ttest1.html",
    "title": "4  One-sample \\(t\\)-test",
    "section": "",
    "text": "In this example, we will use the t.test() function to perform a one-sample \\(t\\)-test. The data set we will use is the mtcars data set, which contains information about 32 different cars. We will use the mpg variable, which is the miles per gallon for each car. We will test the hypothesis that the mean miles per gallon for all cars is 20.",
    "crumbs": [
      "Inference",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>One-sample $t$-test</span>"
    ]
  },
  {
    "objectID": "031-ttest2.html",
    "href": "031-ttest2.html",
    "title": "5  Two-sample \\(t\\)-test",
    "section": "",
    "text": "In summary, this book has no content whatsoever.",
    "crumbs": [
      "Inference",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Two-sample $t$-test</span>"
    ]
  },
  {
    "objectID": "032-nonparametric1.html",
    "href": "032-nonparametric1.html",
    "title": "6  Non-parametrics tests: part 1",
    "section": "",
    "text": "In summary, this book has no content whatsoever.",
    "crumbs": [
      "Inference",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Non-parametrics tests: part 1</span>"
    ]
  },
  {
    "objectID": "033-nonparametric2.html",
    "href": "033-nonparametric2.html",
    "title": "7  # Non-parametrics tests: part 2",
    "section": "",
    "text": "In summary, this book has no content whatsoever.",
    "crumbs": [
      "Inference",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Non-parametrics tests: part 2</span>"
    ]
  },
  {
    "objectID": "040-describing_relationships.html",
    "href": "040-describing_relationships.html",
    "title": "8  Describing relationships",
    "section": "",
    "text": "In summary, this book has no content whatsoever.",
    "crumbs": [
      "Modelling",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Describing relationships</span>"
    ]
  },
  {
    "objectID": "041-linear_functions.html",
    "href": "041-linear_functions.html",
    "title": "9  Linear functions",
    "section": "",
    "text": "In summary, this book has no content whatsoever.",
    "crumbs": [
      "Modelling",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Linear functions</span>"
    ]
  },
  {
    "objectID": "042-linear_functions_multi.html",
    "href": "042-linear_functions_multi.html",
    "title": "10  Linear functions – multiple predictors",
    "section": "",
    "text": "In summary, this book has no content whatsoever.",
    "crumbs": [
      "Modelling",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Linear functions -- multiple predictors</span>"
    ]
  },
  {
    "objectID": "043-nonlinear.html",
    "href": "043-nonlinear.html",
    "title": "11  Non-linear functions",
    "section": "",
    "text": "In summary, this book has no content whatsoever.",
    "crumbs": [
      "Modelling",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Non-linear functions</span>"
    ]
  }
]